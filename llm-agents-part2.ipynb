{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"dzeHYa5GCxN7"},"outputs":[],"source":["# MIT License\n","#\n","# @title Copyright (c) 2024 Mauricio Tec { display-mode: \"form\" }\n","\n","# Permission is hereby granted, free of charge, to any person obtaining a\n","# copy of this software and associated documentation files (the \"Software\"),\n","# to deal in the Software without restriction, including without limitation\n","# the rights to use, copy, modify, merge, publish, distribute, sublicense,\n","# and/or sell copies of the Software, and to permit persons to whom the\n","# Software is furnished to do so, subject to the following conditions:\n","#\n","# The above copyright notice and this permission notice shall be included in\n","# all copies or substantial portions of the Software.\n","#\n","# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n","# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n","# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL\n","# THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n","# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n","# FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n","# DEALINGS IN THE SOFTWARE."]},{"cell_type":"markdown","metadata":{"id":"13i7KQ9t-CV8"},"source":["\n","# Welcome to the HDSI Winter Workshop on LLMs as Autonomous Agents\n","\n","\n","<img src=\"https://drive.google.com/uc?export=view&id=1q4SGPmn6sWQhskt4D-1D09q_6C9FDz_L\" alt=\"drawing\" width=\"400\"/>\n","\n","\n","# **Part II: Grounding Agents with Fine-tuning and RL**\n","\n","<a target=\"_blank\" href=\"https://colab.research.google.com/github/mauriciogtec/hdsi-winter-workshop/blob/main/llm-agents-part2.ipynb\">\n","  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n","</a>\n","\n","Expected completion time: 1 hour\n","\n","\n","## March 6, 2025  <br> Mauricio Tec\n","\n"]},{"cell_type":"markdown","source":["**TL;DR** Our previous tutorial gave us the tools to understand agentic LLM workflows. In this tutorial we will talk about learning. We will use fine tuning and reinforcement learning to improve the LLM for specific tasks.\n","\n","ğŸ”¥ğŸ”¥ ğŸ“š **Let's learn how to learn** ğŸ“šğŸ”¥ğŸ”¥\n","\n","*Familiarity with PyTorch models is assumed.*\n","\n","\n","<br>\n","\n","\n","<img src=\"https://drive.google.com/uc?export=view&id=1e3nRrx9IT5BjhWFwk1VKHS-a6m0EoMhc\" alt=\"drawing\" width=\"450\"/>\n","\n","\n","See also:\n","\n","* [Previous (Part I): Introduction to Agentic Frameworks](https://colab.research.google.com/github/mauriciogtec/hdsi-winter-workshop/blob/main/llm-agents-part1.ipynb)\n","* [Pre-assignment: Setup LLM Access & API Keys](https://colab.research.google.com/github/mauriciogtec/hdsi-winter-workshop/blob/main/pre-assignment.ipynb)\n"],"metadata":{"id":"rMVhWY7bxfNl"}},{"cell_type":"markdown","source":["# Software Prerequisites & Setup\n"],"metadata":{"id":"BPO_LtqGh2jr"}},{"cell_type":"markdown","source":["## Utility Function: Markdown Printing\n","\n","As in part I, we will define a very simple utility function to print nicely in a colab notebook environment with Markdown. This is not really needed, but it will make some output visualizations easier and nicer.\n"],"metadata":{"id":"ggb8xlQ9uPF9"}},{"cell_type":"code","source":["from IPython.display import Markdown, display\n","\n","def printmd(string):\n","    display(Markdown(string))\n","\n","test = \"`This is code`. *This is italics*. **This is bold**.\"\n","printmd(test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":45},"id":"w79rez5guLTw","executionInfo":{"status":"ok","timestamp":1741146875616,"user_tz":300,"elapsed":107,"user":{"displayName":"Mauricio Tec","userId":"14576222252759708863"}},"outputId":"38cf73fa-85c0-4a02-8d6d-3fa0fc3536af"},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"`This is code`. *This is italics*. **This is bold**."},"metadata":{}}]},{"cell_type":"markdown","source":["## Install Requirements\n","\n","* The main tool will be `PyTorch`, which is the most common deep learning research framework.\n","\n","<img src=\"https://upload.wikimedia.org/wikipedia/commons/9/96/Pytorch_logo.png\" alt=\"drawing\" width=\"300\"/>\n","\n","\n","* Our second main tool, more specific to this tutorial, is the  `transformers` library, which provides access to various open-source `LLMs` as PyTorch. With transformers we have access to their internals, code, and weights.\n","* The `HuggingFace` tool ecosystem includes various other packages that we will need to be able to manipulate such massive models, which go beyond standard neural network training. Examples include `peft`, `bitsandbytes`, `accelerate`. For reinforcement learning and finetuning, we will use the `trl` library, which includes functionality for finetuning.\n","\n","<img src=\"https://drive.google.com/uc?export=view&id=1RGuWtGHW88vk7T5JyMjnepG9YzwKJEVM\" alt=\"drawing\" width=\"600\"/>\n","\n","\n","* ğŸ® Let's play a game! While the techniques we will study apply to many environments. We will base our tutorial one nice text-based game called `TextWorld`.  \n","\n","<img src=\"https://drive.google.com/uc?export=view&id=1fdfrUd4gxsute0b6qRdZ5d6l4y16D6UK\" alt=\"drawing\" width=\"600\"/>\n"],"metadata":{"id":"J4gJrYdPoAXX"}},{"cell_type":"code","source":["%pip install -q \\\n","  transformers[torch,accelerate] \\\n","  trl[peft,quantization] \\\n","  textworld-express"],"metadata":{"id":"-m6L0kyHhzoL","executionInfo":{"status":"ok","timestamp":1741146841093,"user_tz":300,"elapsed":73057,"user":{"displayName":"Mauricio Tec","userId":"14576222252759708863"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"c033c0e2-8bcd-4294-cfa3-9e25c2f2fc9e"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/1.5 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.3/1.5 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m485.4/485.4 kB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m121.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m90.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m58.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m40.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m90.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m76.1/76.1 MB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"markdown","source":["## Setup HuggingFace\n","\n","We will be working with the `meta-llama/Llama-3.2-1B-Instruct` model. Let us check access.\n","\n","If your access is restricted, check out the [pre-assignment notebook](https://colab.research.google.com/github/mauriciogtec/hdsi-winter-workshop/blob/main/pre-assignment.ipynb) for more details on setting up access to Llama 3.2 on HuggingFace.\n",""],"metadata":{"id":"KlIToEbRRP0y"}},{"cell_type":"code","source":["import os\n","from google.colab import userdata\n","import transformers\n","\n","# Retrieve open AI key from Colab secrets\n","os.environ[\"HF_TOKEN\"] = userdata.get('HF_TOKEN')\n","\n","model_id = \"meta-llama/Llama-3.2-1B-Instruct\"\n","model = transformers.AutoModelForCausalLM.from_pretrained(model_id)"],"metadata":{"id":"T5n4e4h20cpq","executionInfo":{"status":"ok","timestamp":1741146843012,"user_tz":300,"elapsed":1801,"user":{"displayName":"Mauricio Tec","userId":"14576222252759708863"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["## Setting up the TextWorld Interactive Environment\n","\n","Let's start the fun ğŸ¤©."],"metadata":{"id":"9iqgrWvEaPvt"}},{"cell_type":"code","source":["import random\n","from textworld_express import TextWorldExpressEnv\n","\n","# Initialize game generator\n","env = TextWorldExpressEnv(envStepLimit=100)\n","\n","# Set the game generator to generate a particular game (cookingworld, twc, or coin)\n","env.load(gameName=\"twc\", gameParams=\"numLocations=3,includeDoors=1\")\n","\n","obs, infos = env.reset(seed=1234, gameFold=\"train\", generateGoldPath=True)\n","# Display the observations from the environment.\n","\n","printmd(\"## Welcome to TextWorld\")\n","\n","for step_id in range(0, 10):\n","    printmd(f\"[Obs]: {obs}\")\n","\n","    # Select a random valid action\n","    randomAction = random.choice(infos['validActions'])\n","\n","    # Take that action\n","    obs, reward, done, infos = env.step(randomAction)\n","\n","    # Display action and the game's feedback.\n","    printmd(f\"[Action]: {randomAction}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":548},"id":"sFZzdnLcbh3P","executionInfo":{"status":"ok","timestamp":1741147045289,"user_tz":300,"elapsed":608,"user":{"displayName":"Mauricio Tec","userId":"14576222252759708863"}},"outputId":"216fc028-c6af-43e2-d653-db1f96adc1d9"},"execution_count":18,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"## Welcome to TextWorld"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"[Obs]: You are in the pantry. In one part of the room you see a folding chair, that has nothing on it. There is also a shelf, that has nothing on it. You also see a clean plate. \nTo the East you see a closed plain door. "},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"[Action]: take clean plate"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"[Obs]: You take the clean plate."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"[Action]: close door to east"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"[Obs]: That is already closed. "},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"[Action]: put clean plate in folding chair"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"[Obs]: You put the clean plate in the folding chair."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"[Action]: take clean plate"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"[Obs]: You take the clean plate."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"[Action]: close door to east"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"[Obs]: That is already closed. "},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"[Action]: close door to east"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"[Obs]: That is already closed. "},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"[Action]: put clean plate in shelf"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"[Obs]: You put the clean plate in the shelf."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"[Action]: move east"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"[Obs]: You can't move there, the door is closed. "},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"[Action]: look around"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"[Obs]: You are in the pantry. In one part of the room you see a folding chair, that has nothing on it. There is also a shelf that has a clean plate on it. \nTo the East you see a closed plain door. "},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"[Action]: move east"},"metadata":{}}]},{"cell_type":"markdown","source":["# Conclusion\n","\n","### ğŸ¤— What did we learn? ğŸ¤”\n","\n","* ğŸªœ In an agentic framework, a problem is solved step by step.\n","* ğŸ†˜ LLMs are trained for text completion only. Hence, they struggle at simple operations such as counting or arithmetic which are not aligned with the next-token prediction training.\n","* ğŸ™‡â€â™‚ï¸ They can immediately solve more complex task by *thinking step by step*. We can implement it with the chain-of-thought prompting technique.\n","* ğŸ› ï¸ By leveraging their ability to call tools (code or JSON), we can fill the gap in their abilities. We can implement it with a simple react loop, which underlies most agentic frameworks.\n","\n","\n","### â¡ï¸ Next steps â¡ï¸\n","\n","* ğŸ’¾ More sophisticated memory: in the examples, we simply use the thought, observation, action history as the agent's memory. But for long sequences, we can use a RAG agent. Remember, each token costs money\n","\n","* ğŸ‘¯ So far, we have approached the problem in a single-agent way. But many agentic frameworks allow to have multiple agents. A simple design is having an orchestrator agent which uses other agents as tools, but there are many use cases and designs.\n","\n","* ğŸ¤– In the next part of the tutorial, we will cover how to improve an agent performance with fine tuning and reinforcement learning.\n","\n","\n","\n","\n","<img src=\"https://drive.google.com/uc?export=view&id=1gA9lNXqJunfai38RS6DSRenuXKFysHW6\" alt=\"drawing\" width=\"400\"/>\n"],"metadata":{"id":"hPFpzaD_gyOM"}}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[{"file_id":"1VpgUrL9b971Zx3TIGnlDuDuD8_8aSZo2","timestamp":1740795910938},{"file_id":"17oQqcbIJeM3EIruP4T2ju_-LNQmuqqYg","timestamp":1740539043540},{"file_id":"1rKHeTu4U_CU87_Kwt4MI7yrL7VGHW9hS","timestamp":1717121824388},{"file_id":"https://github.com/mauriciogtec/vlmrl/blob/main/vlmrl.ipynb","timestamp":1713063913073}],"machine_shape":"hm","toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}